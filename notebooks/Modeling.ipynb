{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8eb9357-03ca-45ef-9691-82368b98b595",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910d5b19-7612-4c55-94c7-e7b5e098fe03",
   "metadata": {},
   "source": [
    "Notebook for modeling and testing these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e6b69c0-325b-4ffa-8feb-3c31f953a3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SET RANDOM SEED HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daa8d712-ea0e-4465-be43-4395fe3df402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "\n",
    "#utils.py imports\n",
    "from projecttools.utils import featureEngineeringKavinV1\n",
    "from projecttools.utils import model_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0863ad5d-b2b6-47c2-b3a6-91fb06fbf53f",
   "metadata": {},
   "source": [
    "#### Training-Testing Data Split\n",
    "\n",
    "Used across all versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0cbb2e9-234f-48cb-ac82-8d38be68729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data read + process\n",
    "mycwd = os.getcwd()\n",
    "os.chdir(\"..\")\n",
    "df = pd.read_csv(\"data/\" + \"adult.data\", \n",
    "            index_col=False, \n",
    "            names=['age', \n",
    "                   'workclass', \n",
    "                   'fnlwgt', \n",
    "                   'education', \n",
    "                   'education-num', \n",
    "                   'marital-status', \n",
    "                   'occupation', \n",
    "                   'relationship', \n",
    "                   'race', \n",
    "                   'sex', \n",
    "                   'capital-gain', \n",
    "                   'capital-loss',\n",
    "                   'hours-per-week',\n",
    "                   'native-country',\n",
    "                   'income'])\n",
    "os.chdir(mycwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e813eb6-acea-4eeb-8255-f0af165efb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = df.iloc[:, :-1]\n",
    "testing = df.iloc[: , -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5eca831-5684-4b9c-9cd7-be8be4d99ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(training, testing, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694f3321-f06d-4cee-bcd9-385a6b2cbc11",
   "metadata": {},
   "source": [
    "Now, let us convert these into CSV's for reproducibility and access in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6634e364-4e1a-47c1-bede-0d79987cbde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kavin/hw07-group24/notebooks'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycwd = os.getcwd()\n",
    "mycwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc2837f2-851c-4b61-9d64-e34310871d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train\n",
    "X_train.to_csv(Path(mycwd + \"/TrainingTestingData/v1(Kavin)/X_train.csv\"))\n",
    "\n",
    "#X_test\n",
    "X_test.to_csv(Path(mycwd + \"/TrainingTestingData/v1(Kavin)/X_test.csv\"))\n",
    "\n",
    "#y_train\n",
    "y_train.to_csv(Path(mycwd + \"/TrainingTestingData/v1(Kavin)/y_train.csv\"))\n",
    "\n",
    "#y_test\n",
    "y_test.to_csv(Path(mycwd + \"/TrainingTestingData/v1(Kavin)/y_test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806732e3-a04d-41f5-9647-1cb95856922a",
   "metadata": {},
   "source": [
    "### Modeling Version 1 -- Kavin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90321d0b-8130-4e36-84e7-87744719399f",
   "metadata": {},
   "source": [
    "I will first conduct my data processing using the feature engineering/processing function written in the Version 1 (Kavin) section of the FeatureEngineering notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f592e37d-ad8c-4615-82fa-5db594acfbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data read + process\n",
    "mycwd = os.getcwd()\n",
    "os.chdir(\"..\")\n",
    "df = pd.read_csv(\"data/\" + \"adult.data\", \n",
    "            index_col=False, \n",
    "            names=['age', \n",
    "                   'workclass', \n",
    "                   'fnlwgt', \n",
    "                   'education', \n",
    "                   'education-num', \n",
    "                   'marital-status', \n",
    "                   'occupation', \n",
    "                   'relationship', \n",
    "                   'race', \n",
    "                   'sex', \n",
    "                   'capital-gain', \n",
    "                   'capital-loss',\n",
    "                   'hours-per-week',\n",
    "                   'native-country',\n",
    "                   'income'])\n",
    "os.chdir(mycwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b3e38-c83a-4481-8c76-5bc92bbbc848",
   "metadata": {},
   "source": [
    "#### Feature Engineered data using utils.py function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37b4ee28-e7d8-4a64-b978-adcd227b8c94",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'capital-gain log transformed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._maybe_get_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._unpack_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'capital-gain log transformed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-68d14cd6b96a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfe_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatureEngineeringKavinV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfe_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfe_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/projecttools/utils.py\u001b[0m in \u001b[0;36mfeatureEngineeringKavinV1\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"years educated / hours worked\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"years in education log transformed\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hours-per-week log transformed\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"capital gains * age\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"capital-gain log transformed\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"age log transformed\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m#income\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'capital-gain log transformed'"
     ]
    }
   ],
   "source": [
    "fe_df = featureEngineeringKavinV1(df)\n",
    "training = fe_df.iloc[:, :-1]\n",
    "testing = fe_df.iloc[: , -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9539fdc0-2bee-42ed-baec-2324dcc0d3aa",
   "metadata": {},
   "source": [
    "#### Training-Testing Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d68d29-7f7c-45b8-9d87-d15522ffc416",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(training, testing, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a38297f-d13f-4fee-933c-2bd278eadbb6",
   "metadata": {},
   "source": [
    "Now, let us convert these into CSV's for reproducibility and access in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fec9832-2ea6-4b30-9263-27828cad50eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycwd = os.getcwd()\n",
    "mycwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e988ff9-c5d1-4380-9b48-0d32a5544696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train\n",
    "X_train.to_csv(Path(mycwd + \"/TrainingTestingData/v1(Kavin)/X_train.csv\"))\n",
    "\n",
    "#X_test\n",
    "X_test.to_csv(Path(mycwd + \"/TrainingTestingData/v1(Kavin)/X_test.csv\"))\n",
    "\n",
    "#y_train\n",
    "y_train.to_csv(Path(mycwd + \"/TrainingTestingData/v1(Kavin)/y_train.csv\"))\n",
    "\n",
    "#y_test\n",
    "y_test.to_csv(Path(mycwd + \"/TrainingTestingData/v1(Kavin)/y_test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843c6430-00c1-4168-bb2d-2263b858eb8d",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada94689-b26d-4749-8407-4dd4a400adbe",
   "metadata": {},
   "source": [
    "##### We will use a Random Forest model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46816f94-7f8e-4bc8-b0b4-b388ab0803d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=1)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred_train = regressor.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc31d3f4-619b-47e0-86cf-fc44a4dcd397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Prediction\n",
    "y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67067b-7208-47ca-a032-42bf478a824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Prediction\n",
    "y_pred_test = regressor.predict(X_test)\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546e8e4c-ad77-4f6a-8331-85995be402e2",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ac367-0841-4776-86d3-f267cd696515",
   "metadata": {},
   "source": [
    "Now, let us test our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3b2108-2587-4635-af5a-5ba592cac15f",
   "metadata": {},
   "source": [
    "We will use the utils.py function model_eval that lets us see how our model did and gives us various performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb01046d-ea34-41ad-8276-ff1d808ef0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval(y_train, y_test, y_pred_train, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24cdd1d-b243-4180-9a44-386dc1bf8a25",
   "metadata": {},
   "source": [
    "##### The below is for testing datasets.\n",
    "\n",
    "The precision and recall scores are fairly high at ~0.9 and F1 is also at ~0.9, which is to be expected due to it being a combination of precision and recall. \n",
    "\n",
    "However, it seems accuracy is a bit lower at ~0.85. This indicates to me that my model performs okay, though it could be better. I suspect that there may be a bit of overfitting occurring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8833c7d-69a5-4313-a2ec-cf70627d7f8a",
   "metadata": {},
   "source": [
    "##### The below is for training datasets.\n",
    "\n",
    "Accuracy, precision, recall, and F1 all experience extremely high scores of ~0.98, making me think my training data may be a bit overfitted. Perhaps I could remove some of the overlapping features or mess with the hyper-parameters of the random forest classifier to prevent this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07423c61-d2bf-4fa6-b443-cd1bb793bec3",
   "metadata": {},
   "source": [
    "##### Now, let us quickly store our model as a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779e8910-e929-4d34-97c6-1d2536b1011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(regressor, filename=\"../models/kavin_model_v1.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d389aece-5d44-43c9-9c1c-30d9b1285751",
   "metadata": {},
   "source": [
    "### Modeling Version 2 -- Naomi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837766cc-9226-4c48-af38-a02cfdf5f348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c14246e-9f74-453f-b696-fb159ae22b93",
   "metadata": {},
   "source": [
    "### Modeling Version 3 -- George"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a3ecc-0bcb-48e6-98f5-92bbab7fecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from projecttools.utils import model_eval, feat_eng_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff2f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/adult.data\",\n",
    "                   names = ['age', 'workclass', 'fnlwgt', 'education','education-num',\n",
    "                            'marital-status','occupation','relationship','race','sex',\n",
    "                           'capital-gain','capital-loss','hours-per-week',\n",
    "                            'native-country','income'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2abc34",
   "metadata": {},
   "source": [
    "Drop `education`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\"education\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed76dae",
   "metadata": {},
   "source": [
    "Separate the independent and dependent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c24b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"income\", axis = 1)\n",
    "y = data[\"income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee758b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34a4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e088d7a6",
   "metadata": {},
   "source": [
    "Use the `feat_eng_split` utils function to:\n",
    "\n",
    "1. Split the data into training and testing dataset.\n",
    "\n",
    "2. Feature engineer the training dataset (scale and one hot encode)\n",
    "\n",
    "3. Transform the testing dataset using the rules created by the training dataset.\n",
    "\n",
    "4. Output the transformed training features and labels and the testing features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a72f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = feat_eng_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a01e7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf06e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d3e3d3",
   "metadata": {},
   "source": [
    "The validation dataset will be used to evaluate our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa99933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6302d67a",
   "metadata": {},
   "source": [
    "Check the null accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3135607",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(y_train, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc945504",
   "metadata": {},
   "source": [
    "Null accuracy of 76%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a9c4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfd1aa79",
   "metadata": {},
   "source": [
    "### Plan\n",
    "\n",
    "1. Evaluate how well KNN and Decision Trees do on the data.\n",
    "\n",
    "2. Derive the best (using parameter tuning) version each model.\n",
    "\n",
    "3. Then combine the two tuned models into one ensemble model using stacking.\n",
    "\n",
    "4. Evaluate how well this stacked model does on the validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cca9ea",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a6a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearch KNN\n",
    "\n",
    "param_grid = {\"n_neighbors\":np.arange(3, 21, 2)}\n",
    "\n",
    "grid_knn = GridSearchCV(estimator=KNeighborsClassifier(), \n",
    "                        param_grid=param_grid, scoring=\"accuracy\", cv = 10, verbose = 3)\n",
    "\n",
    "grid_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7ee77f",
   "metadata": {},
   "source": [
    "Best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617e19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_knn.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f441c6",
   "metadata": {},
   "source": [
    "Best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d7b7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_knn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cd345b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6027af3",
   "metadata": {},
   "source": [
    "Grab the best estimator, make predictions on the training and validations and then use the `model_eval` function to compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6f0f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn = grid_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fbfc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_knn_preds = best_knn.predict(X_train)\n",
    "valid_knn_preds = best_knn.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2166f35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_performance = model_eval(y_train, y_valid, train_knn_preds, valid_knn_preds)\n",
    "knn_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a3c5e3",
   "metadata": {},
   "source": [
    "There doesn't seem to be significant overfitting but scores are certainly lower than I'd like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4818e37e",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9475eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search decision trees\n",
    "param_grid = {\"max_depth\": np.arange(5, 40, 2)}\n",
    "\n",
    "grid_dt = GridSearchCV(estimator=DecisionTreeClassifier(random_state=1), \n",
    "                        param_grid=param_grid, scoring=\"accuracy\", cv = 10, verbose = 3)\n",
    "\n",
    "grid_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ea670",
   "metadata": {},
   "source": [
    "Best params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3904804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_dt.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1746c4c1",
   "metadata": {},
   "source": [
    "Best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e281aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_dt.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da8ef7d",
   "metadata": {},
   "source": [
    "Grab best dt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7cc497",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dt = grid_dt.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b179cf",
   "metadata": {},
   "source": [
    "Make predictions on training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06731d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dt_preds = best_dt.predict(X_train)\n",
    "valid_dt_preds = best_dt.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123fe263",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_performance = model_eval(y_train, y_valid, train_dt_preds, valid_dt_preds)\n",
    "dt_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146d448c",
   "metadata": {},
   "source": [
    "The DT model has virtually the same accuracy score as KNN, but has a much better precision score and worse recall score.\n",
    "\n",
    "Decision trees are better at minimizing the false positives (people classified as low income but not) while KNN is better at minimizing the false negatives (people classified as high income but not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16075e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e33df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c96588db",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "\n",
    "In this part we are going to combine our two KNN and DT models along with a logisic regression which will be our final estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba231aec",
   "metadata": {},
   "source": [
    "Collect models into list of tuple pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f2fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [(\"knn\", best_knn),\n",
    "         (\"dt\", best_dt)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8989d94e",
   "metadata": {},
   "source": [
    "Intialize stacking classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0556b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = StackingClassifier(estimators=models, final_estimator=LogisticRegression(random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c15f93",
   "metadata": {},
   "source": [
    "Fit model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e5f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f60e8c",
   "metadata": {},
   "source": [
    "Classify training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack_preds = stack.predict(X_train)\n",
    "valid_stack_preds = stack.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963ed57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_performance = model_eval(y_train, y_valid, train_stack_preds, valid_stack_preds)\n",
    "stack_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af655fe",
   "metadata": {},
   "source": [
    "Let's compare this with the knn and dt results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe89eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f566a326",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9c0433",
   "metadata": {},
   "source": [
    "The stacked model:\n",
    "\n",
    "   - Showed improvement in the f1 scores.\n",
    "   - Not much improvement over the two other accuracy scores.\n",
    "   - Has virtually the same recall score as knn.\n",
    "   - But has a worse precision score than dt\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b9848e",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7940db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(stack, filename=\"../models/george_stack_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9247585d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16d032de-69c2-4e4b-9f98-7734b40e5a97",
   "metadata": {},
   "source": [
    "### Modeling Version 4 -- Winston"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49023d83-aae4-4ba5-9216-2b898daeb73f",
   "metadata": {},
   "source": [
    "For verison 4 of our modeling process, we mvoe to a new branch of machine learning in neural networks.  In this part, I will be training a two hidden layer ne"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
