{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8819d4b6-a920-457d-a33b-e0e9ec11acd7",
   "metadata": {},
   "source": [
    "# Main Narrative Notebook -- Predicting Income Off of General Census Data, a STAT 159 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0ca905-1ce6-4ffe-a9e8-7f9e92134b9e",
   "metadata": {},
   "source": [
    "## EDA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3b3353c-d0da-4127-92d6-ba6484165cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aed0963-5034-4061-bb57-097764871ef0",
   "metadata": {},
   "source": [
    "## Feature Engineering Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee9a8e8-9296-43c4-9c6c-68b9d22c9d0c",
   "metadata": {},
   "source": [
    "Now let us go over Feature Engineering best practices that we have found across our various versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c087801-886d-4f65-af69-bf0a719d1309",
   "metadata": {},
   "source": [
    "### Version 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08248fad-9448-4aac-950b-2c973fa593d6",
   "metadata": {},
   "source": [
    "Version 1 has a lot of standard, to-be-expected feature engineering, along with some interesting approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5602aff8-697f-4862-88d7-b3ea626b0191",
   "metadata": {},
   "source": [
    "##### Let us start with the standard stuff. \n",
    "\n",
    "There is a lot of one-hot encoding for the categorical variables included in the dataset. This lets us use numerical inputs for our model instead of the strings the categorical variables originally stored. \n",
    "\n",
    "Another fairly standard feature-engineering method used is log-transforms. These are especially useful for numerical variables where the later numbers need less weightage than the earlier numbers. This method was used on the following variables: age, years in education, capital-gain, capital-loss, and hours worked per week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f14fef2-7672-45af-8c7f-428794375a28",
   "metadata": {},
   "source": [
    "##### Now, let us talk about some less standard, interesting methods used.\n",
    "\n",
    "Version 1 utilized combined features, meaning it combined different features through various methods. The purpose of this is that a feature may be stronger in terms of model performance if two correlated features are combined and used as a single feature within a model. These very well may have contributed to the solid performance of the version 1 model.\n",
    "\n",
    "The combined features used were: years educated / hours worked and capital gains * age. Years educated / hours worked is interesting, as higher years educated are correlated with less hours worked, so this correlation creates larger or higher values of the ratio. Additionally for capital gains * age, there is a positive relationship between the two, so multiplying amplifies the affect.\n",
    "\n",
    "It should be noted that the ratios utilized used the log versions of the original continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b78c2ba-a8db-4dd3-b77c-dacee3e52f1e",
   "metadata": {},
   "source": [
    "##### There were some miscellaneous changes as well.\n",
    "\n",
    "The target variable was one-hot encoded to be <=50k as a binary variable. Additionally, all the variables that were one-hot encoded or used for log transforms were dropped, as they were not needed for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe3c5c9-cd96-49f3-a22f-4dbefa471d67",
   "metadata": {},
   "source": [
    "### Version 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7131cdb6-ea82-4ae6-8509-74b037b8d63d",
   "metadata": {},
   "source": [
    "Version 2 takes a simple/classical, but efficient approach to feature engineering. Sometimes doing less is more for feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f78aef-04e5-4cbc-a66d-aa7b2fa48197",
   "metadata": {},
   "source": [
    "##### Let us start with the standard stuff. \n",
    "\n",
    "Version 2 made the excellent observation that the dataset uses \"?\" instead of NA values, which is not obvious if checking for NA's via standard Pandas functions. Version 2 made the decision to drop these NA values, which contrasts the decision made in Version 3, where the choice to not drop these NA's was made. Regardless, there is no right or wrong in this scenario and dropping them was a solid decision.\n",
    "\n",
    "Next, all the appropriate categorical variables were one-hot encoded. Additionally, the original, unmodified versions of features were dropped from the dataset, as they have no use in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc95386-e3ed-4194-92de-830c24352192",
   "metadata": {},
   "source": [
    "##### Now, let us talk about some less standard, interesting methods used.\n",
    "\n",
    "One super interesting thing about Version 2 is that they noticed that the data in the target variable (income level) was imbalanced and chose to resample to account for this. This is a very unique method to use in feature engineering to account for an imbalance.\n",
    "\n",
    "Additionally, standardized data scaling was used for the continuous variables. This is an interesting way to weight the importance of continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3db7048-49ec-4c29-8122-57341f279d41",
   "metadata": {},
   "source": [
    "### Version 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8bafae-5eb3-4081-8438-a7275e76757c",
   "metadata": {},
   "source": [
    "Version 3 is very methodical and goes in-depth into more standard feature engineering practices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aff3441-3d44-40ed-9e43-8079d8028d41",
   "metadata": {},
   "source": [
    "##### Let us start with the standard stuff. \n",
    "\n",
    "Version 3 made the excellent choice to check for non-standard NA coding. If one does a cursory check of the data with pandas functions, it would look like there are no NA values. However, Version 3 checked for NA values in different forms and it turns out the data uses \"?\" for its NA values. Version 3 made the decision to not impute these ? variables, as the difference is probably neglibile.\n",
    "\n",
    "Next, Version 3 makes the choice to cut out any redundant features within the dataset. The most prominent ones being the number of years spent in education and highest education, as they essentially convey the same information. The highest education variable ended up being dropped.\n",
    "\n",
    "Next, the target variable was encoded to become binary instead of being <=50k and >50k. Next, the categorical variables were one-hot encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede0969e-4845-4231-a468-773ec57afed5",
   "metadata": {},
   "source": [
    "##### Now, let us talk about some less standard, interesting methods used.\n",
    "\n",
    "The utilization of a fit_transform was interesting, where the data was first fit and then transformed. Another super interesting method used was a StandardScaler object, where a fit-transform was used on the continuous variables to standardize them. The choice to standardize them is interesting, as it is a safe way to transform continuous variables as opposed to doing log transforms, like in the version 1 example.\n",
    "\n",
    "Overall, this feature engineering process was made to be very clean and generalizable. It should perform well across many models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeaccb9-3477-4ed4-8920-2de3f553d3f2",
   "metadata": {},
   "source": [
    "### Version 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07d767-68c5-49f4-ae2f-bb24a8dcceb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fe3418-2f82-4821-9e18-a6d558acd331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42f568f-466e-4dda-b352-d29483c1e4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "181ba209-8b6b-41cd-9c0b-3e3e06267e60",
   "metadata": {},
   "source": [
    "### Best Feature Engineering Practices Learned Across Versions 1, 2, 3, and 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21afd6a6-e57a-452f-b347-88b489154c3a",
   "metadata": {},
   "source": [
    "Now let us discuss the best feature engineering practices found across Versions 1, 2, 3, and 4 and how they can be applied together in future approaches to this census income problem or even similar ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70138628-6e1b-4f92-a2c4-091d6c989367",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "The first thing we will be discussing is not strictly feature engineering, but it is an important thing to think about. Datasets are not always standardized. In this particular example, there are no NA values, yet there are still blank rows that use \"?\" instead of NA. These don't appear under standard Pandas functions, but are still important. In feature engineering, it is important to account for these non-standardized datasets. Whether we choose to impute or use other methods is another story, but looking for these little details can go a long away in our feature engineering efforts and eventual model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e65116-fbc2-4174-8c51-1eb16e1a7801",
   "metadata": {},
   "source": [
    "2.\n",
    "\n",
    "One-hot encoding is a fairly obvious feature engineering effort, but is important nonetheless. Making sure to \"numerify\" categorical variables is super important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaec9f-b4c4-4440-b003-74adf6734432",
   "metadata": {},
   "source": [
    "3.\n",
    "\n",
    "Cutting redundancy is important in feature engineering. If two features essentially communicate the same thing, removing one will help improve efficiency of the model and prevent the overweighting of a feature genre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f346a573-f51b-4b4a-99fc-c89541022900",
   "metadata": {},
   "source": [
    "4.\n",
    "\n",
    "Standardizing the features is another interesting method. It helps to reduce the range of the values and weights values different based on how close they are to the center. This could give extrema less of an impact on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea429ea-c13d-4b38-95b5-6d56cc516bf1",
   "metadata": {},
   "source": [
    "5.\n",
    "\n",
    "In a similar vein to number 4, applying log transforms to features is a great practice in feature engineering. Some features, such as age, have diminishing returns as the values get higher. In these situations, applying a log-transform to make jumps in lower values to be weighted more can be helpful and change the way extrema are viewed by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d6f8f2-b0ce-4a7c-b46b-69bcbba3ed8d",
   "metadata": {},
   "source": [
    "6.\n",
    "\n",
    "Another great practice is combine features if they have some sort of correlation. For example, in version 1 there was a ratio of years educated / hours worked. These two features have a high correlation and combining two such features can potentially make models perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da65a2ea-c1cd-4122-b93a-cd62b5d1fece",
   "metadata": {},
   "source": [
    "## Modeling/Testing Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07c93014-236c-43ee-8239-75bd43dcee7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ddfa04-98c5-4021-83a2-9044938bc242",
   "metadata": {},
   "source": [
    "## Final Model and Results\n",
    "\n",
    "In this section we find out if pooling our four different approaches can combine together to produce a signifcantly better model.\n",
    "\n",
    "Steps:\n",
    "\n",
    "   1. Each member's model and feature engineering methods are loaded into this notebook\n",
    "   2. Make a train test split on the data\n",
    "   3. Train each member's model on the training data.\n",
    "   4. Classify the testing dataset with each model. Show each model's performance.\n",
    "   5. Ensemble model:\n",
    "       - Generate prediction probabilities for model.\n",
    "       - Average them.\n",
    "       - Using a 0.5 threshold turn probability into classifications.\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0914a6b1-17b0-42ef-b405-362e65ab016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d1d51b-9a55-43a5-bb2a-462cfb8565ad",
   "metadata": {},
   "source": [
    "**George**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "51d3cc82-4f4d-42e8-8590-5d247934620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/adult.data\",\n",
    "                   names = ['age', 'workclass', 'fnlwgt', 'education','education-num',\n",
    "                            'marital-status','occupation','relationship','race','sex',\n",
    "                           'capital-gain','capital-loss','hours-per-week',\n",
    "                            'native-country','income'])\n",
    "\n",
    "X = data.drop([\"education\", \"income\"], axis = 1)\n",
    "y = data[\"income\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d9daf3-3985-4af3-84b7-0bbde3857235",
   "metadata": {},
   "source": [
    "Load in feature engineering utils function and apply it to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c566abb8-2dbf-4d52-bf87-6d3051a1a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projecttools.utils import feat_eng_split, model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "10afd220-20eb-40ce-9b48-bb740eef4b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = feat_eng_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9862fe4d-8761-44be-9690-599a60d0c7bb",
   "metadata": {},
   "source": [
    "Load in model and fit it on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1d6aaadd-5849-46cf-9e17-0fa6ca8a1fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.24.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.24.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StackingClassifier from version 0.24.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('knn', KNeighborsClassifier(n_neighbors=17)),\n",
       "                               ('dt',\n",
       "                                DecisionTreeClassifier(max_depth=9,\n",
       "                                                       random_state=1))],\n",
       "                   final_estimator=LogisticRegression(random_state=1))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "george_model = joblib.load(\"models/george_stack_model.joblib\")\n",
    "george_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2875755a-97f2-428d-923a-5d2914aad25d",
   "metadata": {},
   "source": [
    "Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "18e9a4c4-9551-4de4-b1b8-4c6284509b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "george_train_preds = george_model.predict(X_train)\n",
    "george_test_preds = george_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "40b94261-a3ae-41fa-80d1-1c7f2d59885f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training</th>\n",
       "      <th>Testing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy Score</th>\n",
       "      <td>0.876986</td>\n",
       "      <td>0.860459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.804316</td>\n",
       "      <td>0.757500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.646489</td>\n",
       "      <td>0.618367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.716817</td>\n",
       "      <td>0.680899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Training   Testing\n",
       "Accuracy Score   0.876986  0.860459\n",
       "Precision Score  0.804316  0.757500\n",
       "Recall           0.646489  0.618367\n",
       "F1 Score         0.716817  0.680899"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "george_performance = model_eval(y_train, y_test, george_train_preds, george_test_preds)\n",
    "george_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1610acb0-a403-4b77-8875-f039c57d565c",
   "metadata": {},
   "source": [
    "Generate probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "323b6f51-4190-46b8-9c8d-fd18c4d32437",
   "metadata": {},
   "outputs": [],
   "source": [
    "george_train_probs = george_model.predict_proba(X_train)[:, 1]\n",
    "george_test_probs = george_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f747ec-a01d-4a1a-926d-de401959e461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd47df1d-37d9-4077-8f85-f416f77251fe",
   "metadata": {},
   "source": [
    "**Kavin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "83482953-16cc-4e11-b8d9-686545d5ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projecttools.utils import featureEngineeringKavinV1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d962b41d-bdec-49bc-a873-b759b2d2a7ef",
   "metadata": {},
   "source": [
    "Transform features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "abba1a75-2713-4f27-a4c1-ed43042ac93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>?</th>\n",
       "      <th>Federal-gov</th>\n",
       "      <th>Local-gov</th>\n",
       "      <th>Never-worked</th>\n",
       "      <th>Private</th>\n",
       "      <th>Self-emp-inc</th>\n",
       "      <th>Self-emp-not-inc</th>\n",
       "      <th>State-gov</th>\n",
       "      <th>Without-pay</th>\n",
       "      <th>10th</th>\n",
       "      <th>...</th>\n",
       "      <th>United-States</th>\n",
       "      <th>Vietnam</th>\n",
       "      <th>Yugoslavia</th>\n",
       "      <th>age log transformed</th>\n",
       "      <th>years in education log transformed</th>\n",
       "      <th>hours-per-week log transformed</th>\n",
       "      <th>capital-gain log transformed</th>\n",
       "      <th>capital-loss log transformed</th>\n",
       "      <th>years educated / hours worked</th>\n",
       "      <th>capital gains * age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>7.684784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.710652</td>\n",
       "      <td>28.348242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.663562</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620046</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.988984</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.559957</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.710652</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ?   Federal-gov   Local-gov   Never-worked   Private   Self-emp-inc  \\\n",
       "0   0             0           0              0         0              0   \n",
       "1   0             0           0              0         0              0   \n",
       "2   0             0           0              0         1              0   \n",
       "3   0             0           0              0         1              0   \n",
       "4   0             0           0              0         1              0   \n",
       "\n",
       "    Self-emp-not-inc   State-gov   Without-pay   10th  ...   United-States  \\\n",
       "0                  0           1             0      0  ...               1   \n",
       "1                  1           0             0      0  ...               1   \n",
       "2                  0           0             0      0  ...               1   \n",
       "3                  0           0             0      0  ...               1   \n",
       "4                  0           0             0      0  ...               0   \n",
       "\n",
       "    Vietnam   Yugoslavia  age log transformed  \\\n",
       "0         0            0             3.688879   \n",
       "1         0            0             3.931826   \n",
       "2         0            0             3.663562   \n",
       "3         0            0             3.988984   \n",
       "4         0            0             3.367296   \n",
       "\n",
       "   years in education log transformed  hours-per-week log transformed  \\\n",
       "0                            2.639057                        3.713572   \n",
       "1                            2.639057                        2.639057   \n",
       "2                            2.302585                        3.713572   \n",
       "3                            2.079442                        3.713572   \n",
       "4                            2.639057                        3.713572   \n",
       "\n",
       "   capital-gain log transformed  capital-loss log transformed  \\\n",
       "0                      7.684784                           0.0   \n",
       "1                      0.000000                           0.0   \n",
       "2                      0.000000                           0.0   \n",
       "3                      0.000000                           0.0   \n",
       "4                      0.000000                           0.0   \n",
       "\n",
       "   years educated / hours worked  capital gains * age  \n",
       "0                       0.710652            28.348242  \n",
       "1                       1.000000             0.000000  \n",
       "2                       0.620046             0.000000  \n",
       "3                       0.559957             0.000000  \n",
       "4                       0.710652             0.000000  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = featureEngineeringKavinV1(data)\n",
    "y = X.iloc[:, -1].astype(int)\n",
    "X = X.iloc[:, :-1]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ca3299a3-0e31-48e0-8979-4a56f1f7f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=1, stratify= y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "48b6730b-57b7-47a9-9126-ca24a81f555b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.24.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "kavin_model = joblib.load(\"models/kavin_model_v1.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9869fa04-35c7-4ad7-8dd0-94ca1278ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "kavin_model = RandomForestClassifier(n_estimators = 20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f19f27a7-286e-4df2-b2f6-40179681dfcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=20, random_state=1)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kavin_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c54b6a9-d64f-4bc9-a2ed-9e99d301aac0",
   "metadata": {},
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "16c5f681-0cfc-4866-a042-17bfeea0a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "kavin_train_preds = kavin_model.predict(X_train)\n",
    "kavin_test_preds = kavin_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b3c790-1d7d-4fe8-9021-42d43a0ca0a0",
   "metadata": {},
   "source": [
    "Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d541d3f7-1e3d-4009-b463-0d325b607bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training</th>\n",
       "      <th>Testing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy Score</th>\n",
       "      <td>0.976536</td>\n",
       "      <td>0.840806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.982438</td>\n",
       "      <td>0.884706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.986731</td>\n",
       "      <td>0.908753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.984580</td>\n",
       "      <td>0.896568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Training   Testing\n",
       "Accuracy Score   0.976536  0.840806\n",
       "Precision Score  0.982438  0.884706\n",
       "Recall           0.986731  0.908753\n",
       "F1 Score         0.984580  0.896568"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kavin_performance = model_eval(y_train, y_test, kavin_train_preds, kavin_test_preds)\n",
    "kavin_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5349f2b5-9746-44db-9aed-dcea973b1409",
   "metadata": {},
   "source": [
    "Generate probailities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9d7d94a8-e969-4eb1-af8e-c82d850663e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kavin_train_probs = kavin_model.predict_proba(X_train)[:, 1]\n",
    "kavin_test_probs = kavin_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec039db3-aeee-4c88-aa63-ec59a35d4d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdfff8b3-4a8a-42fb-bd0f-a73abcd5cff6",
   "metadata": {},
   "source": [
    "**Naomi**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01df986b-a534-4c8b-8a9c-72e99f554796",
   "metadata": {},
   "source": [
    "Replicate Naomi's feature engineering process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0b1841e1-c506-460c-8443-7767cd936d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6f1e1f16-576c-45b7-a14f-8c4afbdaa5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/adult.data\",\n",
    "                   names = ['age', 'workclass', 'fnlwgt', 'education','education-num',\n",
    "                           'marital-status','occupation','relationship','race','sex',\n",
    "                          'capital-gain','capital-loss','hours-per-week',\n",
    "                            'native-country','income'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e9acd7e5-c250-4552-a72e-393f72ddde20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "for col in data.columns:\n",
    "    if data[col].dtypes == 'object':\n",
    "        encoder = LabelEncoder()\n",
    "        data[col] = encoder.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "22f8c0c0-8374-40e6-8161-1130cd089053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>77516</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>83311</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>215646</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>234721</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>338409</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
       "0   39          7   77516          9             13               4   \n",
       "1   50          6   83311          9             13               2   \n",
       "2   38          4  215646         11              9               0   \n",
       "3   53          4  234721          1              7               2   \n",
       "4   28          4  338409          9             13               2   \n",
       "\n",
       "   occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "0           1             1     4    1          2174             0   \n",
       "1           4             0     4    1             0             0   \n",
       "2           6             1     4    1             0             0   \n",
       "3           6             0     2    1             0             0   \n",
       "4          10             5     2    0             0             0   \n",
       "\n",
       "   hours-per-week  native-country  income  \n",
       "0              40              39       0  \n",
       "1              13              39       0  \n",
       "2              40              39       0  \n",
       "3              40              39       0  \n",
       "4              40               5       0  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "46069149-0104-4d82-b0e0-9ab4eb7e972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['workclass', 'education', 'race', 'sex', 'capital-loss',\n",
    "        'native-country', 'income'], axis = 1)\n",
    "y = data[\"income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3195601d-9f76-43f7-a651-b90d3ef06913",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)\n",
    "Xs = pd.DataFrame(index=X.index, data= Xs, columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c73fc929-0184-46e4-8dba-9d4198f45f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size = 0.25, random_state=1, stratify= y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4e118e60-dd4c-4e88-9a39-5a6a074bc42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "naomi_model = joblib.load(\"models/naomi_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5d7ff014-4267-4305-bf8f-a93c8c01b18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True, random_state=1)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naomi_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "33db110c-f873-4e1a-827a-459445eb3d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "naomi_train_preds = naomi_model.predict(X_train)\n",
    "naomi_test_preds = naomi_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0f1b34e7-81f1-4047-9e30-aa049f96bae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training</th>\n",
       "      <th>Testing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy Score</th>\n",
       "      <td>0.850041</td>\n",
       "      <td>0.844491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.775379</td>\n",
       "      <td>0.756657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.531202</td>\n",
       "      <td>0.521939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.630474</td>\n",
       "      <td>0.617754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Training   Testing\n",
       "Accuracy Score   0.850041  0.844491\n",
       "Precision Score  0.775379  0.756657\n",
       "Recall           0.531202  0.521939\n",
       "F1 Score         0.630474  0.617754"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naomi_performance = model_eval(y_train, y_test, naomi_train_preds, naomi_test_preds)\n",
    "naomi_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d1c328f5-cd2f-4f8c-8b85-430d9a746eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "naomi_train_probs = naomi_model.predict_proba(X_train)[:, 1]\n",
    "naomi_test_probs = naomi_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37813e20-adca-4153-aac4-20860ba680fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d73ccd-a3b5-45ec-972c-7e4d672f87ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c7d68b-c67a-42cd-b0f9-5511e7dfa78f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a929160f-d6ba-40a4-a435-320b84d4e03c",
   "metadata": {},
   "source": [
    "**Winston**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f025af28-dd30-42d9-aae6-dc320c360160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd2e5c6f-73d5-4fbc-97a2-f839849f190e",
   "metadata": {},
   "source": [
    "**Ensemble**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0a9d56-c9fc-44a5-a395-fc3f23889226",
   "metadata": {},
   "source": [
    "Collect the four sets of probabilites into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363a48ed-1165-450f-8da2-2a53356833f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c049d09a-ed19-4cf4-9936-df09b2a06d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_probs = pd.DataFrame({\"george\":george_train_probs,\n",
    "                               \"kavin\": kavin_train_probs,\n",
    "                                \"naomi\": naomi_train_probs})\n",
    "\n",
    "ensemble_test_probs = pd.DataFrame({\"george\":george_test_probs,\n",
    "                               \"kavin\": kavin_test_probs,\n",
    "                                \"naomi\": naomi_test_probs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f2edb39d-c8e2-4e53-b314-63d8c611695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_train_preds = ensemble_train_probs.mean(axis = 1).apply(lambda x: 1 if x>=0.5 else 0)\n",
    "ensemble_test_preds = ensemble_test_probs.mean(axis = 1).apply(lambda x: 1 if x>=0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4d38905c-877d-46b8-8479-920d9218dcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training</th>\n",
       "      <th>Testing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy Score</th>\n",
       "      <td>0.859623</td>\n",
       "      <td>0.845105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.715364</td>\n",
       "      <td>0.686201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.692739</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.703870</td>\n",
       "      <td>0.671358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Training   Testing\n",
       "Accuracy Score   0.859623  0.845105\n",
       "Precision Score  0.715364  0.686201\n",
       "Recall           0.692739  0.657143\n",
       "F1 Score         0.703870  0.671358"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_performance = model_eval(y_train, y_test, ensemble_train_preds, ensemble_test_preds)\n",
    "ensemble_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bc941a-5aea-4e78-b380-69d829817254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5a3a28-1c05-419e-b71d-15d9bfd73f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa797f5-1677-4785-aa0e-ae67327272d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f895db1b-cdd6-4dd4-a29f-78a73bfac003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dc4364a-095b-4456-9331-a47c4bd1e61e",
   "metadata": {},
   "source": [
    "Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807e7219-9e55-4f7b-9ee2-6d0574b0ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_performance = model_eval(y_train, y_test, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e941026-6ce1-4578-a686-906d6f70e158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d71127-30c0-4c41-8e63-fd93d83cc245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e903c4a3-2a4e-47fb-9650-8e6ba85f0ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa140b43-0a50-4c19-befd-8f39e401ac20",
   "metadata": {},
   "source": [
    "## Author Contributions Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfeb6bd-3b66-4bd8-8dec-479804033d20",
   "metadata": {},
   "source": [
    "Kavin:\n",
    "\n",
    "* Version 1 -- EDA.ipynb, FeatureEngineering.ipynb, Modeling.ipynb\n",
    "* Makefile\n",
    "* README.md\n",
    "* Feature Engineering Analysis -- main.ipynb\n",
    "* Repository Structuring\n",
    "* Initializing + Formatting Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83b56fb-20c9-46e5-94a0-4f0efaf3a709",
   "metadata": {},
   "source": [
    "George McIntire:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8f0b5c-3847-4e28-9452-0b0526fd39a6",
   "metadata": {},
   "source": [
    "Wen-Ching (Naomi) Tu:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177e4153-cd76-4c24-8926-c9ec3e3f6ff7",
   "metadata": {},
   "source": [
    "Winston Cai:\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
